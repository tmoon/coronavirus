{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.dates import date2num, num2date\n",
    "from matplotlib import dates as mdates\n",
    "from matplotlib import ticker\n",
    "from matplotlib.colors import ListedColormap\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "from scipy import stats as sps\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "FILTERED_REGION_CODES = ['AS', 'GU', 'PR', 'VI', 'MP']\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib.dates import date2num, num2date\n",
    "from matplotlib import dates as mdates\n",
    "\n",
    "from scipy import stats as sps\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "\n",
    "def batch_estimate_rt(data_list, region_name_list, serial_interval=7, cutoff=10, rtmax=12, ci_pct=0.9):\n",
    "    '''\n",
    "    this is just a wrapper around estimate_rt. see the docstring for estimate_rt for documentation\n",
    "    \n",
    "    data_list:        a list of data parameter accepted by estimate_rt\n",
    "    region_name_list: a list of region_name parameter accepted by estimate_rt\n",
    "\n",
    "    return: a list of rts for each region in data_list\n",
    "    '''\n",
    "    assert(len(data_list) == len(region_name_list))\n",
    "    rt_list = []\n",
    "    for data, region_name in zip(data_list, region_name_list):\n",
    "        rt = estimate_rt(data, region_name, serial_interval, cutoff, rtmax, ci_pct)\n",
    "        rt_list.append(rt)\n",
    "\n",
    "    return rt_list\n",
    "\n",
    "\n",
    "\n",
    "def estimate_rt(data, region_name, serial_interval=7, cutoff=10, rtmax=12, ci_pct=0.9):\n",
    "    '''\n",
    "    data: pandas DataFrame of date and number of tested positives (cumulative). read data from csv with \n",
    "          the following command\n",
    "\n",
    "    data = pd.read_csv(\n",
    "        filepath\n",
    "        usecols=[0, 1],\n",
    "        parse_dates=[0],\n",
    "        index_col=[0],\n",
    "        names=['date', 'positive'],\n",
    "        header=None,\n",
    "        skiprows=1,\n",
    "        squeeze=False,\n",
    "    ).sort_index() \n",
    "\n",
    "    serial_interval: serial interval of covid -19\n",
    "    cutoff:          threshold for number of new positive cases to be detected on a single day.\n",
    "    rtmax:           max allowed value for Rt   \n",
    "    \n",
    "    returns: a pandas Dataframe of date, ML estimate of Rt and ci_pct error bounds. (default: 90%) \n",
    "    '''\n",
    "    gamma = 1/serial_interval\n",
    "    rt_range = np.linspace(0, rtmax, rtmax * 100 + 1)\n",
    "\n",
    "    \n",
    "    print(f\"estimating Rt for {region_name}...\")\n",
    "\n",
    "    cases = data['positive']\n",
    "    sigmas = np.linspace(1 / 20, 1, 20)\n",
    "\n",
    "    new, smoothed = prepare_cases(cases, cutoff=cutoff)\n",
    "    result = {}\n",
    "\n",
    "    # Holds all posteriors with every given value of sigma\n",
    "    result['posteriors'] = []\n",
    "\n",
    "    # Holds the log likelihood across all k for each value of sigma\n",
    "    result['log_likelihoods'] = []\n",
    "    \n",
    "    for sigma in sigmas:\n",
    "        posteriors, log_likelihood = get_posteriors(smoothed, gamma, rt_range, sigma=sigma)\n",
    "        result['posteriors'].append(posteriors)\n",
    "        result['log_likelihoods'].append(log_likelihood)\n",
    "\n",
    "\n",
    "    total_log_likelihoods = result['log_likelihoods']\n",
    "\n",
    "    # Select the index with the largest log likelihood total\n",
    "    max_likelihood_index = np.argmax(total_log_likelihoods)\n",
    "\n",
    "    # Select the value that has the highest log likelihood\n",
    "    sigma = sigmas[max_likelihood_index]\n",
    "\n",
    "    posteriors = result['posteriors'][max_likelihood_index]\n",
    "    hdis = highest_density_interval(posteriors, p=ci_pct)\n",
    "    most_likely = posteriors.idxmax().rename('ML')\n",
    "    result = pd.concat([most_likely, hdis], axis=1)\n",
    "\n",
    "    return result.iloc[1:].reset_index()\n",
    "\n",
    "\n",
    "def highest_density_interval(pmf, p=0.9, debug=False):\n",
    "    # If we pass a DataFrame, just call this recursively on the columns\n",
    "    if isinstance(pmf, pd.DataFrame):\n",
    "        return pd.DataFrame(\n",
    "            [highest_density_interval(pmf[col], p=p) for col in pmf], index=pmf.columns\n",
    "        )\n",
    "\n",
    "    cumsum = np.cumsum(pmf.values)\n",
    "    # N x N matrix of total probability mass for each low, high\n",
    "    total_p = cumsum - cumsum[:, None]\n",
    "\n",
    "    # Return all indices with total_p > p\n",
    "    lows, highs = (total_p > p).nonzero()\n",
    "\n",
    "    # Find the smallest range (highest density)\n",
    "    best = (highs - lows).argmin()\n",
    "\n",
    "    low = pmf.index[lows[best]]\n",
    "    high = pmf.index[highs[best]]\n",
    "\n",
    "    return pd.Series([low, high], index=[f'Low_{p*100:.0f}', f'High_{p*100:.0f}'])\n",
    "\n",
    "\n",
    "def prepare_cases(cases, cutoff=5):\n",
    "    new_cases = cases.diff()\n",
    "    # NOTE: CHANGED HERE\n",
    "#     smoothed = new_cases.rolling(7, win_type='gaussian', min_periods=1, center=True).mean(std=2).round()\n",
    "    smoothed = new_cases.rolling(7, min_periods=1).mean(std=2).round()\n",
    "    \n",
    "    \n",
    "    idx_start = 0\n",
    "    for idx in range(len(cases)):\n",
    "        if smoothed.iloc[idx] >= cutoff:\n",
    "            idx_start = idx\n",
    "            break\n",
    "#     idx_start = np.searchsorted(smoothed.values, cutoff)\n",
    "    # NOTE: END OF CHANGED\n",
    "    \n",
    "    smoothed = smoothed.iloc[idx_start:]\n",
    "    original = new_cases.loc[smoothed.index]\n",
    "    return original, smoothed\n",
    "\n",
    "def get_posteriors(sr, gamma, rt_range, sigma=0.15):\n",
    "\n",
    "    # (1) Calculate Lambda\n",
    "    lam = sr[:-1].values * np.exp(gamma * (rt_range[:, None] - 1))\n",
    "\n",
    "    # (2) Calculate each day's likelihood\n",
    "    likelihoods = pd.DataFrame(\n",
    "        data=sps.poisson.pmf(sr[1:].values, lam), index=rt_range, columns=sr.index[1:]\n",
    "    )\n",
    "\n",
    "    # (3) Create the Gaussian Matrix\n",
    "    process_matrix = sps.norm(loc=rt_range, scale=sigma).pdf(rt_range[:, None])\n",
    "\n",
    "    # (3a) Normalize all rows to sum to 1\n",
    "    process_matrix /= process_matrix.sum(axis=0)\n",
    "\n",
    "    # (4) Calculate the initial prior\n",
    "    # prior0 = sps.gamma(a=4).pdf(rt_range)\n",
    "    prior0 = np.ones_like(rt_range) / len(rt_range)\n",
    "    prior0 /= prior0.sum()\n",
    "\n",
    "    # Create a DataFrame that will hold our posteriors for each day\n",
    "    # Insert our prior as the first posterior.\n",
    "    posteriors = pd.DataFrame(index=rt_range, columns=sr.index, data={sr.index[0]: prior0})\n",
    "\n",
    "    # We said we'd keep track of the sum of the log of the probability\n",
    "    # of the data for maximum likelihood calculation.\n",
    "    log_likelihood = 0.0\n",
    "\n",
    "    # (5) Iteratively apply Bayes' rule\n",
    "    for previous_day, current_day in zip(sr.index[:-1], sr.index[1:]):\n",
    "\n",
    "        # (5a) Calculate the new prior\n",
    "        current_prior = process_matrix @ posteriors[previous_day]\n",
    "\n",
    "        # (5b) Calculate the numerator of Bayes' Rule: P(k|R_t)P(R_t)\n",
    "        numerator = likelihoods[current_day] * current_prior\n",
    "\n",
    "        # (5c) Calcluate the denominator of Bayes' Rule P(k)\n",
    "        denominator = np.sum(numerator)\n",
    "\n",
    "        # Execute full Bayes' Rule\n",
    "        posteriors[current_day] = numerator / denominator\n",
    "\n",
    "        # Add to the running sum of log likelihoods\n",
    "        log_likelihood += np.log(denominator)\n",
    "\n",
    "    return posteriors, log_likelihood\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>district_city</th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-04-13</th>\n",
       "      <td>হবিগঞ্জ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-13</th>\n",
       "      <td>জামালপুর</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-13</th>\n",
       "      <td>নারায়ণগঞ্জ</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-13</th>\n",
       "      <td>নেত্রকোনা</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-13</th>\n",
       "      <td>লক্ষ্মীপুর</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           district_city  positive\n",
       "date                              \n",
       "2020-04-13       হবিগঞ্জ         1\n",
       "2020-04-13      জামালপুর         6\n",
       "2020-04-13   নারায়ণগঞ্জ       144\n",
       "2020-04-13     নেত্রকোনা         1\n",
       "2020-04-13    লক্ষ্মীপুর         1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"bd_rt_data/2020-06-04/district_cases.csv\",\n",
    "                usecols=[0, 1, 2],\n",
    "        parse_dates=[0],\n",
    "        index_col=[0],\n",
    "        names=['date', 'district_city', 'positive'],\n",
    "        header=None,\n",
    "        skiprows=1,\n",
    "        squeeze=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'কক্সবাজার',\n",
       " 'কিশোরগঞ্জ',\n",
       " 'কুমিল্লা',\n",
       " 'গাজীপুর',\n",
       " 'গোপালগঞ্জ',\n",
       " 'চট্টগ্রাম',\n",
       " 'জামালপুর',\n",
       " 'ঢাকা',\n",
       " 'নরসিংদী',\n",
       " 'নারায়ণগঞ্জ',\n",
       " 'নেত্রকোনা',\n",
       " 'নোয়াখালী',\n",
       " 'ময়মনসিংহ',\n",
       " 'মাদারীপুর',\n",
       " 'মুন্সিগঞ্জ',\n",
       " 'যশোর',\n",
       " 'রংপুর',\n",
       " 'লক্ষ্মীপুর',\n",
       " 'সিলেট',\n",
       " 'হবিগঞ্জ'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(df.district_city)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>district_city</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>মাদারীপুর</th>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>লক্ষ্মীপুর</th>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>যশোর</th>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>গোপালগঞ্জ</th>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>হবিগঞ্জ</th>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>নরসিংদী</th>\n",
       "      <td>176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>জামালপুর</th>\n",
       "      <td>206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>নেত্রকোনা</th>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>কিশোরগঞ্জ</th>\n",
       "      <td>233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>সিলেট</th>\n",
       "      <td>292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>রংপুর</th>\n",
       "      <td>415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ময়মনসিংহ</th>\n",
       "      <td>489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>নোয়াখালী</th>\n",
       "      <td>574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>গাজীপুর</th>\n",
       "      <td>635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>কক্সবাজার</th>\n",
       "      <td>636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>মুন্সিগঞ্জ</th>\n",
       "      <td>698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>কুমিল্লা</th>\n",
       "      <td>771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>নারায়ণগঞ্জ</th>\n",
       "      <td>2057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>চট্টগ্রাম</th>\n",
       "      <td>2288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ঢাকা</th>\n",
       "      <td>16922</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               positive\n",
       "district_city          \n",
       "মাদারীপুর           115\n",
       "লক্ষ্মীপুর          140\n",
       "যশোর                144\n",
       "গোপালগঞ্জ           168\n",
       "হবিগঞ্জ             173\n",
       "নরসিংদী             176\n",
       "জামালপুর            206\n",
       "নেত্রকোনা           211\n",
       "কিশোরগঞ্জ           233\n",
       "সিলেট               292\n",
       "রংপুর               415\n",
       "ময়মনসিংহ           489\n",
       "নোয়াখালী           574\n",
       "গাজীপুর             635\n",
       "কক্সবাজার           636\n",
       "মুন্সিগঞ্জ          698\n",
       "কুমিল্লা            771\n",
       "নারায়ণগঞ্জ        2057\n",
       "চট্টগ্রাম          2288\n",
       "ঢাকা              16922"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(\"district_city\").max().sort_values(\"positive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_df_dict = {d: df[df.district_city == d].copy() for d in set(df.district_city)}\n",
    "rt_df_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "গোপালগঞ্জ\n",
      "estimating Rt for গোপালগঞ্জ...\n",
      "লক্ষ্মীপুর\n",
      "estimating Rt for লক্ষ্মীপুর...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarik/.local/share/virtualenvs/alakazam-hdvw4kJ2/lib/python3.6/site-packages/scipy/stats/_discrete_distns.py:598: RuntimeWarning: invalid value encountered in greater_equal\n",
      "  return mu >= 0\n",
      "/Users/tarik/misc/coronavirus/realtime_Rt.py:179: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/tarik/misc/coronavirus/realtime_Rt.py:104: RuntimeWarning: invalid value encountered in greater\n",
      "  lows, highs = (total_p > p).nonzero()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "লক্ষ্মীপুর attempt to get argmin of an empty sequence\n",
      "নেত্রকোনা\n",
      "estimating Rt for নেত্রকোনা...\n",
      "ঢাকা\n",
      "estimating Rt for ঢাকা...\n",
      "ময়মনসিংহ\n",
      "estimating Rt for ময়মনসিংহ...\n",
      "নোয়াখালী\n",
      "estimating Rt for নোয়াখালী...\n",
      "যশোর\n",
      "estimating Rt for যশোর...\n",
      "যশোর attempt to get argmin of an empty sequence\n",
      "হবিগঞ্জ\n",
      "estimating Rt for হবিগঞ্জ...\n",
      "হবিগঞ্জ attempt to get argmin of an empty sequence\n",
      "রংপুর\n",
      "estimating Rt for রংপুর...\n",
      "কুমিল্লা\n",
      "estimating Rt for কুমিল্লা...\n",
      "মুন্সিগঞ্জ\n",
      "estimating Rt for মুন্সিগঞ্জ...\n",
      "মাদারীপুর\n",
      "estimating Rt for মাদারীপুর...\n",
      "মাদারীপুর attempt to get argmin of an empty sequence\n",
      "সিলেট\n",
      "estimating Rt for সিলেট...\n",
      "নারায়ণগঞ্জ\n",
      "estimating Rt for নারায়ণগঞ্জ...\n",
      "কক্সবাজার\n",
      "estimating Rt for কক্সবাজার...\n",
      "গাজীপুর\n",
      "estimating Rt for গাজীপুর...\n",
      "গাজীপুর attempt to get argmin of an empty sequence\n",
      "নরসিংদী\n",
      "estimating Rt for নরসিংদী...\n",
      "জামালপুর\n",
      "estimating Rt for জামালপুর...\n",
      "চট্টগ্রাম\n",
      "estimating Rt for চট্টগ্রাম...\n",
      "কিশোরগঞ্জ\n",
      "estimating Rt for কিশোরগঞ্জ...\n",
      "কিশোরগঞ্জ attempt to get argmin of an empty sequence\n"
     ]
    }
   ],
   "source": [
    "for d in set(df.district_city):\n",
    "    try:\n",
    "        print(d)\n",
    "        rt_df_dict[d] = estimate_rt(dist_df_dict[d], d)\n",
    "    except Exception as e:\n",
    "        print(d, e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Failed: \n",
    "\n",
    "লক্ষ্মীপুর attempt to get argmin of an empty sequence\n",
    "যশোর attempt to get argmin of an empty sequence\n",
    "হবিগঞ্জ attempt to get argmin of an empty sequence\n",
    "মাদারীপুর attempt to get argmin of an empty sequence\n",
    "গাজীপুর attempt to get argmin of an empty sequence\n",
    "কিশোরগঞ্জ attempt to get argmin of an empty sequence\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "atlas",
   "language": "python",
   "name": "atlas"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
