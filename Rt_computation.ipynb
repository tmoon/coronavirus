{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "atlas",
      "language": "python",
      "name": "atlas"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "Rt_computation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "IfqMPP1gKmu9",
        "colab_type": "code",
        "outputId": "f65a2132-ce73-491d-edda-77ef31c5e273",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!git clone https://github.com/tmoon/coronavirus.git"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'coronavirus' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OuVfuGs9KewS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "from matplotlib.dates import date2num, num2date\n",
        "from matplotlib import dates as mdates\n",
        "from matplotlib import ticker\n",
        "from matplotlib.colors import ListedColormap\n",
        "from matplotlib.patches import Patch\n",
        "\n",
        "from scipy import stats as sps\n",
        "from scipy.interpolate import interp1d\n",
        "\n",
        "from IPython.display import clear_output\n",
        "\n",
        "FILTERED_REGION_CODES = ['AS', 'GU', 'PR', 'VI', 'MP']\n",
        "\n",
        "%config InlineBackend.figure_format = 'retina'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WD8XD4upKewZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sys\n",
        "import traceback\n",
        "\n",
        "from matplotlib.dates import date2num, num2date\n",
        "from matplotlib import dates as mdates\n",
        "\n",
        "from scipy import stats as sps\n",
        "from scipy.interpolate import interp1d\n",
        "\n",
        "\n",
        "def batch_estimate_rt(data_list, region_name_list, serial_interval=7, cutoff=10, rtmax=12, ci_pct=0.9):\n",
        "    '''\n",
        "    this is just a wrapper around estimate_rt. see the docstring for estimate_rt for documentation\n",
        "    \n",
        "    data_list:        a list of data parameter accepted by estimate_rt\n",
        "    region_name_list: a list of region_name parameter accepted by estimate_rt\n",
        "\n",
        "    return: a list of rts for each region in data_list\n",
        "    '''\n",
        "    assert(len(data_list) == len(region_name_list))\n",
        "    rt_list = []\n",
        "    for data, region_name in zip(data_list, region_name_list):\n",
        "        rt = estimate_rt(data, region_name, serial_interval, cutoff, rtmax, ci_pct)\n",
        "        rt_list.append(rt)\n",
        "\n",
        "    return rt_list\n",
        "\n",
        "\n",
        "\n",
        "def estimate_rt(data, region_name, serial_interval=7, cutoff=10, rtmax=12, ci_pct=0.9):\n",
        "    '''\n",
        "    data: pandas DataFrame of date and number of tested positives (cumulative). read data from csv with \n",
        "          the following command\n",
        "\n",
        "    data = pd.read_csv(\n",
        "        filepath\n",
        "        usecols=[0, 1],\n",
        "        parse_dates=[0],\n",
        "        index_col=[0],\n",
        "        names=['date', 'positive'],\n",
        "        header=None,\n",
        "        skiprows=1,\n",
        "        squeeze=False,\n",
        "    ).sort_index() \n",
        "\n",
        "    serial_interval: serial interval of covid -19\n",
        "    cutoff:          threshold for number of new positive cases to be detected on a single day.\n",
        "    rtmax:           max allowed value for Rt   \n",
        "    \n",
        "    returns: a pandas Dataframe of date, ML estimate of Rt and ci_pct error bounds. (default: 90%) \n",
        "    '''\n",
        "    gamma = 1/serial_interval\n",
        "    rt_range = np.linspace(0, rtmax, rtmax * 100 + 1)\n",
        "\n",
        "    \n",
        "    print(f\"estimating Rt for {region_name}...\")\n",
        "\n",
        "    cases = data['positive']\n",
        "    sigmas = np.linspace(1 / 20, 1, 20)\n",
        "\n",
        "    new, smoothed = prepare_cases(cases, cutoff=cutoff)\n",
        "    result = {}\n",
        "\n",
        "    # if not enough cases, send rt=1 with error bars 0, inf\n",
        "    if len(smoothed) == 0:\n",
        "        date = data.reset_index()['date']\n",
        "        ml = np.ones(len(date))\n",
        "        low = np.zeros(len(date))\n",
        "        high = np.ones(len(date))*10\n",
        "        result = pd.DataFrame({\"date\":date, \"ML\":ml, f\"Low_{ci_pct*100:.0f}\":low, f\"High_{ci_pct*100:.0f}\":high})\n",
        "        return result\n",
        "\n",
        "\n",
        "    # Holds all posteriors with every given value of sigma\n",
        "    result['posteriors'] = []\n",
        "\n",
        "    # Holds the log likelihood across all k for each value of sigma\n",
        "    result['log_likelihoods'] = []\n",
        "    \n",
        "    for sigma in sigmas:\n",
        "        posteriors, log_likelihood = get_posteriors(smoothed, gamma, rt_range, sigma=sigma)\n",
        "        result['posteriors'].append(posteriors)\n",
        "        result['log_likelihoods'].append(log_likelihood)\n",
        "\n",
        "\n",
        "    total_log_likelihoods = result['log_likelihoods']\n",
        "\n",
        "    # Select the index with the largest log likelihood total\n",
        "    max_likelihood_index = np.argmax(total_log_likelihoods)\n",
        "\n",
        "    # Select the value that has the highest log likelihood\n",
        "    sigma = sigmas[max_likelihood_index]\n",
        "\n",
        "    posteriors = result['posteriors'][max_likelihood_index]\n",
        "    assert np.all(np.isfinite(posteriors)), \"All probability density must be finite\"\n",
        "    hdis = highest_density_interval(posteriors, p=ci_pct)\n",
        "    most_likely = posteriors.idxmax().rename('ML')\n",
        "    result = pd.concat([most_likely, hdis], axis=1)\n",
        "\n",
        "    return result.iloc[1:].reset_index()\n",
        "\n",
        "\n",
        "def highest_density_interval(pmf, p=0.9, debug=False):\n",
        "    # If we pass a DataFrame, just call this recursively on the columns\n",
        "    if isinstance(pmf, pd.DataFrame):\n",
        "        return pd.DataFrame(\n",
        "            [highest_density_interval(pmf[col], p=p) for col in pmf], index=pmf.columns\n",
        "        )\n",
        "\n",
        "    cumsum = np.cumsum(pmf.values)\n",
        "    # N x N matrix of total probability mass for each low, high\n",
        "    total_p = cumsum - cumsum[:, None]\n",
        "\n",
        "    # Return all indices with total_p > p\n",
        "    lows, highs = (total_p > p).nonzero()\n",
        "\n",
        "    # Find the smallest range (highest density)\n",
        "    best = (highs - lows).argmin()\n",
        "\n",
        "    low = pmf.index[lows[best]]\n",
        "    high = pmf.index[highs[best]]\n",
        "\n",
        "    return pd.Series([low, high], index=[f'Low_{p*100:.0f}', f'High_{p*100:.0f}'])\n",
        "\n",
        "\n",
        "def prepare_cases(cases, cutoff=5):\n",
        "    new_cases = cases.diff()\n",
        "    # NOTE: CHANGED HERE\n",
        "#     smoothed = new_cases.rolling(7, win_type='gaussian', min_periods=1, center=True).mean(std=2).round()\n",
        "\n",
        "    # First value of diff is always NaN, so removing that\n",
        "    new_cases = new_cases.dropna()\n",
        "    smoothed = new_cases.rolling(7, min_periods=1).mean(std=2).round()\n",
        "    \n",
        "    assert np.all(np.isfinite(smoothed)), \"All values must be finite\"\n",
        "\n",
        "    idx_start = len(smoothed)\n",
        "    for idx in range(len(smoothed)):\n",
        "        if smoothed.iloc[idx] >= cutoff:\n",
        "            idx_start = idx\n",
        "            break\n",
        "#     idx_start = np.searchsorted(smoothed.values, cutoff)\n",
        "    # NOTE: END OF CHANGED\n",
        "    \n",
        "    smoothed_prev = smoothed.iloc[:]\n",
        "    smoothed = smoothed.iloc[idx_start:]\n",
        "\n",
        "    assert np.all(smoothed > 0.)\n",
        "    original = new_cases.loc[smoothed.index]\n",
        "    return original, smoothed\n",
        "\n",
        "def get_posteriors(sr, gamma, rt_range, sigma=0.15):\n",
        "\n",
        "    # (1) Calculate Lambda\n",
        "    lam = sr[:-1].values * np.exp(gamma * (rt_range[:, None] - 1))\n",
        "\n",
        "    # (2) Calculate each day's likelihood\n",
        "    likelihoods = pd.DataFrame(\n",
        "        data=sps.poisson.pmf(sr[1:].values, lam), index=rt_range, columns=sr.index[1:]\n",
        "    )\n",
        "\n",
        "    # (3) Create the Gaussian Matrix\n",
        "    process_matrix = sps.norm(loc=rt_range, scale=sigma).pdf(rt_range[:, None])\n",
        "\n",
        "    # (3a) Normalize all rows to sum to 1\n",
        "    process_matrix /= process_matrix.sum(axis=0)\n",
        "\n",
        "    # (4) Calculate the initial prior\n",
        "    # prior0 = sps.gamma(a=4).pdf(rt_range)\n",
        "    prior0 = np.ones_like(rt_range) / len(rt_range)\n",
        "    prior0 /= prior0.sum()\n",
        "\n",
        "    # Create a DataFrame that will hold our posteriors for each day\n",
        "    # Insert our prior as the first posterior.\n",
        "    posteriors = pd.DataFrame(index=rt_range, columns=sr.index, data={sr.index[0]: prior0})\n",
        "\n",
        "    # We said we'd keep track of the sum of the log of the probability\n",
        "    # of the data for maximum likelihood calculation.\n",
        "    log_likelihood = 0.0\n",
        "\n",
        "    # (5) Iteratively apply Bayes' rule\n",
        "    for previous_day, current_day in zip(sr.index[:-1], sr.index[1:]):\n",
        "\n",
        "        # (5a) Calculate the new prior\n",
        "        current_prior = process_matrix @ posteriors[previous_day]\n",
        "\n",
        "        # (5b) Calculate the numerator of Bayes' Rule: P(k|R_t)P(R_t)\n",
        "        numerator = likelihoods[current_day] * current_prior\n",
        "\n",
        "        # (5c) Calcluate the denominator of Bayes' Rule P(k)\n",
        "        denominator = np.sum(numerator)\n",
        "\n",
        "        # Execute full Bayes' Rule\n",
        "        posteriors[current_day] = numerator / denominator\n",
        "\n",
        "        # Add to the running sum of log likelihoods\n",
        "        epsilon = 1e-16\n",
        "        log_likelihood += np.log(denominator+epsilon)\n",
        "\n",
        "    return posteriors, log_likelihood\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHjYVFeHKewc",
        "colab_type": "code",
        "outputId": "420534fc-8b43-4a70-f4e5-519e3c2d7aad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        }
      },
      "source": [
        "df = pd.read_csv(\"coronavirus/bd_rt_data/2020-06-04/district_cases.csv\",\n",
        "                usecols=[0, 1, 2],\n",
        "        parse_dates=[0],\n",
        "        index_col=[0],\n",
        "        names=['date', 'district_city', 'positive'],\n",
        "        header=None,\n",
        "        skiprows=1,\n",
        "        squeeze=False)\n",
        "df = df.sort_index()\n",
        "df.head()"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>district_city</th>\n",
              "      <th>positive</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2020-05-08</th>\n",
              "      <td>বগুড়া</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-05-08</th>\n",
              "      <td>নারায়ণগঞ্জ</td>\n",
              "      <td>1136</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-05-08</th>\n",
              "      <td>গাজীপুর</td>\n",
              "      <td>330</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-05-08</th>\n",
              "      <td>ঢাকা</td>\n",
              "      <td>6365</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-05-08</th>\n",
              "      <td>মুন্সিগঞ্জ</td>\n",
              "      <td>210</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           district_city  positive\n",
              "date                              \n",
              "2020-05-08        বগুড়া        18\n",
              "2020-05-08   নারায়ণগঞ্জ      1136\n",
              "2020-05-08       গাজীপুর       330\n",
              "2020-05-08          ঢাকা      6365\n",
              "2020-05-08    মুন্সিগঞ্জ       210"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jiDLgouTKewk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.groupby(\"district_city\").max().sort_values(\"positive\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mboSH2iUfxs-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "011ceb35-41da-4813-d19e-e5d19f23fcc4"
      },
      "source": [
        "dist_df_dict = {d: df[df.district_city == d].copy() for d in set(df.district_city)}\n",
        "rt_df_dict = {}\n",
        "\n",
        "for d in ['হবিগঞ্জ', 'কিশোরগঞ্জ', 'নরসিংদী', 'যশোর', 'নেত্রকোনা']:\n",
        "    try: \n",
        "        rt_df_dict[d] = estimate_rt(dist_df_dict[d], d)\n",
        "        # assert 1 == 0\n",
        "    except Exception as e:\n",
        "        traceback.print_exc()"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "estimating Rt for হবিগঞ্জ...\n",
            "estimating Rt for কিশোরগঞ্জ...\n",
            "estimating Rt for নরসিংদী...\n",
            "estimating Rt for যশোর...\n",
            "estimating Rt for নেত্রকোনা...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-DydvvsKeww",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"Failed: \n",
        "\n",
        "লক্ষ্মীপুর attempt to get argmin of an empty sequence\n",
        "যশোর attempt to get argmin of an empty sequence\n",
        "হবিগঞ্জ attempt to get argmin of an empty sequence\n",
        "মাদারীপুর attempt to get argmin of an empty sequence\n",
        "গাজীপুর attempt to get argmin of an empty sequence\n",
        "কিশোরগঞ্জ attempt to get argmin of an empty sequence\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}